{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='imdb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    load_df = pd.read_csv(path,sep=';')\n",
    "    where=load_df['Id'].iloc[-1]+1\n",
    "except:\n",
    "  where=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords(id):\n",
    "    word=''\n",
    "    key_url='https://www.imdb.com/title/tt'+id+'/keywords/'\n",
    "    #https://www.imdb.com/title/tt'+id_+'/'\n",
    "    response_keyword=requests.get(key_url,headers=headers)\n",
    "    content_keyword=response_keyword.content\n",
    "    soup_keyword=BeautifulSoup(content_keyword,'html.parser')\n",
    "    keyword_elements=soup_keyword.find_all('a',class_='ipc-metadata-list-summary-item__t')\n",
    "    for element in keyword_elements:\n",
    "     word += ', ' + element.text\n",
    "    #print('keyword')\n",
    "    return word[2:len(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_info(id):\n",
    "    key_url='https://www.imdb.com/title/tt'+id+'/releaseinfo/'\n",
    "    #https://www.imdb.com/title/tt'+id_+'/'\n",
    "    response_release_info=requests.get(key_url,headers=headers)\n",
    "    content_release_info=response_release_info.content\n",
    "    soup_release_info=BeautifulSoup(content_release_info,'html.parser')\n",
    "    date=soup_release_info.find('span',class_='ipc-metadata-list-item__list-content-item')\n",
    "    try:\n",
    "       soup_release_info.find('article',class_='sc-8eb80a87-0 hQQXzj').text is not None\n",
    "      # print('release info')\n",
    "       return 'NaN'\n",
    "\n",
    "    except:\n",
    "       #print('release info')\n",
    "       return date.text\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime(id):\n",
    "    key_url='https://www.imdb.com/title/tt'+id+'/technical/'\n",
    "    #https://www.imdb.com/title/tt'+id_+'/'\n",
    "    response_runtime=requests.get(key_url,headers=headers)\n",
    "    content_runtime=response_runtime.content\n",
    "    soup_runtime=BeautifulSoup(content_runtime,'html.parser')\n",
    "    runtime=soup_runtime.find_all('span',class_='ipc-metadata-list-item__list-content-item--subText')\n",
    "    color=soup_runtime.find_all('a',class_='ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link')\n",
    "    try:\n",
    "     return runtime[0].text,color[1].text\n",
    "    except:\n",
    "        return 'NaN',color[1].text\n",
    "           \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df={'Id':[],'Title':[],'Storyline':[],'Director':[],'Date':[],'Runtime':[],'Rating':[],'Color':[],'Country':[],'keywords':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(soup):\n",
    "    r_items = soup.find_all('a', class_='ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link')\n",
    "    inde=0\n",
    "    for r in r_items:\n",
    "  \n",
    "      if r.text == 'None':\n",
    "        country_name= r_items[inde-1].text\n",
    "        break\n",
    "      else:\n",
    "        country_name='NaN'\n",
    "      inde=inde+1\n",
    "    return country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://www.imdb.com/title/tt0000001/ << processing\n",
      "2 https://www.imdb.com/title/tt0000002/ << processing\n",
      "3 https://www.imdb.com/title/tt0000003/ << processing\n",
      "4 https://www.imdb.com/title/tt0000004/ << processing\n",
      "5 https://www.imdb.com/title/tt0000005/ << processing\n",
      "6 https://www.imdb.com/title/tt0000006/ << processing\n",
      "7 https://www.imdb.com/title/tt0000007/ << processing\n",
      "8 https://www.imdb.com/title/tt0000008/ << processing\n",
      "9 https://www.imdb.com/title/tt0000009/ << processing\n",
      "10 https://www.imdb.com/title/tt0000010/ << processing\n",
      "11 https://www.imdb.com/title/tt0000011/ << processing\n",
      "12 https://www.imdb.com/title/tt0000012/ << processing\n",
      "13 https://www.imdb.com/title/tt0000013/ << processing\n",
      "14 https://www.imdb.com/title/tt0000014/ << processing\n",
      "15 https://www.imdb.com/title/tt0000015/ << processing\n",
      "16 https://www.imdb.com/title/tt0000016/ << processing\n",
      "17 https://www.imdb.com/title/tt0000017/ << processing\n",
      "18 https://www.imdb.com/title/tt0000018/ << processing\n",
      "19 https://www.imdb.com/title/tt0000019/ << processing\n",
      "20 https://www.imdb.com/title/tt0000020/ << processing\n",
      "21 https://www.imdb.com/title/tt0000021/ << processing\n",
      "22 https://www.imdb.com/title/tt0000022/ << processing\n",
      "23 https://www.imdb.com/title/tt0000023/ << processing\n",
      "24 https://www.imdb.com/title/tt0000024/ << processing\n",
      "25 https://www.imdb.com/title/tt0000025/ << processing\n",
      "26 https://www.imdb.com/title/tt0000026/ << processing\n",
      "27 https://www.imdb.com/title/tt0000027/ << processing\n",
      "28 https://www.imdb.com/title/tt0000028/ << processing\n",
      "29 https://www.imdb.com/title/tt0000029/ << processing\n",
      "30 https://www.imdb.com/title/tt0000030/ << processing\n",
      "31 https://www.imdb.com/title/tt0000031/ << processing\n",
      "32 https://www.imdb.com/title/tt0000032/ << processing\n",
      "33 https://www.imdb.com/title/tt0000033/ << processing\n",
      "34 https://www.imdb.com/title/tt0000034/ << processing\n",
      "35 https://www.imdb.com/title/tt0000035/ << processing\n",
      "36 https://www.imdb.com/title/tt0000036/ << processing\n",
      "37 https://www.imdb.com/title/tt0000037/ << processing\n",
      "38 https://www.imdb.com/title/tt0000038/ << processing\n",
      "39 https://www.imdb.com/title/tt0000039/ << processing\n",
      "40 https://www.imdb.com/title/tt0000040/ << processing\n",
      "41 https://www.imdb.com/title/tt0000041/ << processing\n",
      "42 https://www.imdb.com/title/tt0000042/ << processing\n",
      "43 https://www.imdb.com/title/tt0000043/ << processing\n",
      "44 https://www.imdb.com/title/tt0000044/ << processing\n",
      "45 https://www.imdb.com/title/tt0000045/ << processing\n",
      "46 https://www.imdb.com/title/tt0000046/ << processing\n",
      "47 https://www.imdb.com/title/tt0000047/ << processing\n",
      "48 https://www.imdb.com/title/tt0000048/ << processing\n",
      "49 https://www.imdb.com/title/tt0000049/ << processing\n",
      "50 https://www.imdb.com/title/tt0000050/ << processing\n",
      "51 https://www.imdb.com/title/tt0000051/ << processing\n",
      "52 https://www.imdb.com/title/tt0000052/ << processing\n",
      "53 https://www.imdb.com/title/tt0000053/ << processing\n",
      "54 https://www.imdb.com/title/tt0000054/ << processing\n",
      "55 https://www.imdb.com/title/tt0000055/ << processing\n",
      "56 https://www.imdb.com/title/tt0000056/ << processing\n",
      "57 https://www.imdb.com/title/tt0000057/ << processing\n",
      "58 https://www.imdb.com/title/tt0000058/ << processing\n",
      "59 https://www.imdb.com/title/tt0000059/ << processing\n",
      "60 https://www.imdb.com/title/tt0000060/ << processing\n",
      "61 https://www.imdb.com/title/tt0000061/ << processing\n",
      "62 https://www.imdb.com/title/tt0000062/ << processing\n",
      "63 https://www.imdb.com/title/tt0000063/ << processing\n",
      "64 https://www.imdb.com/title/tt0000064/ << processing\n",
      "65 https://www.imdb.com/title/tt0000065/ << processing\n",
      "66 https://www.imdb.com/title/tt0000066/ << processing\n",
      "67 https://www.imdb.com/title/tt0000067/ << processing\n",
      "68 https://www.imdb.com/title/tt0000068/ << processing\n",
      "69 https://www.imdb.com/title/tt0000069/ << processing\n",
      "70 https://www.imdb.com/title/tt0000070/ << processing\n",
      "71 https://www.imdb.com/title/tt0000071/ << processing\n",
      "72 https://www.imdb.com/title/tt0000072/ << processing\n",
      "73 https://www.imdb.com/title/tt0000073/ << processing\n",
      "74 https://www.imdb.com/title/tt0000074/ << processing\n",
      "75 https://www.imdb.com/title/tt0000075/ << processing\n",
      "76 https://www.imdb.com/title/tt0000076/ << processing\n",
      "77 https://www.imdb.com/title/tt0000077/ << processing\n",
      "78 https://www.imdb.com/title/tt0000078/ << processing\n",
      "79 https://www.imdb.com/title/tt0000079/ << processing\n",
      "80 https://www.imdb.com/title/tt0000080/ << processing\n",
      "81 https://www.imdb.com/title/tt0000081/ << processing\n",
      "82 https://www.imdb.com/title/tt0000082/ << processing\n",
      "83 https://www.imdb.com/title/tt0000083/ << processing\n",
      "84 https://www.imdb.com/title/tt0000084/ << processing\n",
      "85 https://www.imdb.com/title/tt0000085/ << processing\n",
      "86 https://www.imdb.com/title/tt0000086/ << processing\n",
      "87 https://www.imdb.com/title/tt0000087/ << processing\n",
      "88 https://www.imdb.com/title/tt0000088/ << processing\n",
      "89 https://www.imdb.com/title/tt0000089/ << processing\n",
      "90 https://www.imdb.com/title/tt0000090/ << processing\n",
      "91 https://www.imdb.com/title/tt0000091/ << processing\n",
      "92 https://www.imdb.com/title/tt0000092/ << processing\n",
      "93 https://www.imdb.com/title/tt0000093/ << processing\n",
      "94 https://www.imdb.com/title/tt0000094/ << processing\n",
      "95 https://www.imdb.com/title/tt0000095/ << processing\n",
      "96 https://www.imdb.com/title/tt0000096/ << processing\n",
      "97 https://www.imdb.com/title/tt0000097/ << processing\n",
      "98 https://www.imdb.com/title/tt0000098/ << processing\n",
      "99 https://www.imdb.com/title/tt0000099/ << processing\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:43\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_df' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i=1\n",
    "start_time=time.time()\n",
    "for num in range(where,100000000):\n",
    "                            len_num=7-len(str(num))\n",
    "                            id_='0'*len_num+str(num)\n",
    "                            w_url='https://www.imdb.com/title/tt'+id_+'/'\n",
    "                            try:\n",
    "                              response=requests.get(w_url,headers=headers)\n",
    "                              content=response.content\n",
    "                              soup=BeautifulSoup(content,'html.parser')\n",
    "                              Title=soup.find('span',class_='sc-afe43def-1 fDTGTb').text\n",
    "                            except:\n",
    "                              print(i,w_url,'>> Error')\n",
    "                              continue\n",
    "                            print(i,w_url,'<< processing')\n",
    "                            Title=soup.find('span',class_='sc-afe43def-1 fDTGTb').text\n",
    "                            try:\n",
    "                             storyline=soup.find_all('div',class_='ipc-html-content-inner-div')[2].text\n",
    "                            except:\n",
    "                              storyline='NaN'\n",
    "                            Director=soup.find_all('a',class_='ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link')[0].text\n",
    "                            Date=release_info(id_)\n",
    "                            \n",
    "                            Runtime_,colr=runtime(id_)\n",
    "                            try:\n",
    "                             Rating=(soup.find_all('span',class_='sc-bde20123-1 iZlgcd')[0]).text\n",
    "                            except:\n",
    "                              Rating=\"NaN\"\n",
    "                            country_=country(soup)\n",
    "                            df['Country'].append(country_)\n",
    "                            key_words=keywords(str(id_))\n",
    "                            i=i+1\n",
    "                            df['Id'].append(id_)\n",
    "                            df['Link'].append(w_url)\n",
    "                            df['Title'].append(Title)\n",
    "                            df['Storyline'].append(storyline)\n",
    "                            df['Director'].append(Director)\n",
    "                            df['Date'].append(Date)\n",
    "                            df['Runtime'].append(Runtime_)\n",
    "                            df['Color'].append(colr)\n",
    "                            df['Rating'].append(Rating)\n",
    "                            df['keywords'].append(key_words)\n",
    "                            if i==100:\n",
    "                              try:\n",
    "                               main_df=pd.DataFrame(df)\n",
    "                               save_df=pd.concat([load_df, main_df], ignore_index=True)\n",
    "                               save_df.to_csv(path,index=False,sep=';',header=True)\n",
    "                               load_df = pd.read_csv(path,sep=';')\n",
    "                               print('>>',load_df.shape)\n",
    "                               df={'Id':[],'Link':[],'Title':[],'Storyline':[],'Director':[],'Date':[],'Runtime':[],'Rating':[],'Color':[],'Country':[],'keywords':[]}\n",
    "                               end_time=time.time()\n",
    "                               print('>>Time', (end_time-start_time)/100)\n",
    "                               start_time=time.time()\n",
    "                              except:\n",
    "                                main_df=pd.DataFrame(df)\n",
    "                                save_df=main_df\n",
    "                                save_df.to_csv(path,index=False,sep=';',header=True)\n",
    "                                load_df = pd.read_csv(path,sep=';')\n",
    "                                print('>>',load_df.shape)\n",
    "                                df={'Id':[],'Link':[],'Title':[],'Storyline':[],'Director':[],'Date':[],'Runtime':[],'Rating':[],'Color':[],'Country':[],'keywords':[]}\n",
    "                                print('File not found Solved')\n",
    "\n",
    "                              i=1\n",
    "                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
